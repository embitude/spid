struct dma_chan *dma_request_chan(struct device *dev, const char *name);
void *devm_kcalloc(struct device *dev, size_t n, size_t size, gfp_t flags)

dma_addr_t dma_map_single(struct device *dev, void *ptr, /*buffer*/ size_t size, enum dma_data_direction dir)
enum dma_data_direction {
    DMA_BIDIRECTIONAL = 0,
    DMA_TO_DEVICE = 1,
    DMA_FROM_DEVICE = 2,
    DMA_NONE = 3,
};

static inline int dmaengine_slave_config(struct dma_chan *chan, struct dma_slave_config *config)

void sg_init_table(struct scatterlist *sgl, unsigned int nents)
sg_dma_address(sg)
sg_dma_len(sg)

struct dma_async_tx_descriptor *dmaengine_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl, unsigned int sg_len,
    enum dma_transfer_direction dir, unsigned long flags)
enum dma_transfer_direction {
    DMA_MEM_TO_MEM, 
    DMA_MEM_TO_DEV,
    DMA_DEV_TO_MEM,
    DMA_DEV_TO_DEV,
    DMA_TRANS_NONE,
};

enum dma_ctrl_flags {
    DMA_PREP_INTERRUPT = (1 << 0),
    DMA_CTRL_ACK = (1 << 1),
    DMA_PREP_PQ_DISABLE_P = (1 << 2),
    DMA_PREP_PQ_DISABLE_Q = (1 << 3),
    DMA_PREP_CONTINUE = (1 << 4),
    DMA_PREP_FENCE = (1 << 5),
    DMA_CTRL_REUSE = (1 << 6),
    DMA_PREP_CMD = (1 << 7),
};

dma_cookie_t dmaengine_submit(struct dma_async_tx_descriptor *desc);
void dma_async_issue_pending(struct dma_chan *chan)
void wait_for_completion(struct completion *x)
void complete(struct completion *x)
